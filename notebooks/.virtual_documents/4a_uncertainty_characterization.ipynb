


























import warnings
import pandas as pd
import numpy as np

from SALib.sample import latin, sobol


#First we add the path to the excel file that contains the parameter uncertainty characterization values
input_path = ('Uncertainties.xlsx')

#then we add the download path to store our samples
download_path = ('Samples.xlsx')


#We define a sampling function that draws from the excel file 

def sampling_generator(pavement_system, sampling_method, sample_size, random_seed):
       '''
    Parameters:
    
    pavement system (string) : name of the pavement system/scenario to be sampled as named in the corresponding excel sheet
    sampling_method (string): LHS (Latin hypercube sampling) or Sobol, depending on the GSA method to be applied later on. 
    sample_size (int) : For LHS, number of samples to be generated; for Sobol, baseline sample N in N * (D + 2) 
                                    where ``D`` is the number of parameters
    random_seed (int): seed use to generate samples                            
    
    Returns:
    
    input_df (excel) : Excel containing a dataframe with the generated samples
    
    '''
    #warnings.filterwarnings("ignore")
    #We extract the names, distributions and sample-specific metadata from the excel file required for sampling    
    parameters = pd.DataFrame(pd.read_excel
                        (input_path,
                        sheet_name=pavement_system)) #sheet containing the values of the pavement system (scenario) to sample

    parameters = parameters.round(4)
    
    #we set the bounds to define PDFs according to SALib's convention
    parameters['bounds'] = ''             
    for index in range(len(parameters)):
        if parameters['dist'].loc[index] == 'lognorm':
            parameters['bounds'].loc[index] = [parameters['mean'].loc[index],
                                               parameters['std'].loc[index]]
        elif parameters['dist'].loc[index] in ['unif', 'logunif']:
            parameters['bounds'].loc[index] = [parameters['lower bound'].loc[index],
                                               parameters['upper bound'].loc[index]]
        elif parameters['dist'].loc[index] == 'triang':
            parameters['bounds'].loc[index] = [parameters['lower bound'].loc[index],
                                               parameters['upper bound'].loc[index],
                                               parameters['mean'].loc[index]]
        elif parameters['dist'].loc[index] == 'norm':
            parameters['bounds'].loc[index] = [parameters['mean'].loc[index],
                                               parameters['std'].loc[index]] 
        else:
            parameters['bounds'].loc[index] = [parameters['lower bound'].loc[index],
                                               parameters['upper bound'].loc[index],
                                               parameters['mean'].loc[index],
                                               parameters['std'].loc[index]]
            
    parameters = parameters.set_index('name')
    params = parameters['bounds'].squeeze()
    dists = parameters['dist'].squeeze() #we extract the distributions as a variable
    #bounds=np.array([np.array(i) for i in params.values])
    bounds=[i for i in params]
    num_vars=len(bounds)

    #SALib problem definition and sampling
    problem={'num_vars':num_vars, 'bounds':bounds, 'names':params.index, 'dists':dists.values}
    n=sample_size #Baseline sample size
    if sampling_method == 'Sobol':
        samples=sobol.sample(problem, N=n, calc_second_order=False, seed=random_seed)
    elif sampling_method == 'LHS':
        samples=latin.sample(problem, N=n, seed=random_seed)

    input_df=pd.DataFrame(samples, #store samples as dataframe
                        columns=params.index)
    
    #Save sample dataframe
    with pd.ExcelWriter(download_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
        input_df.to_excel(writer, sheet_name = pavement_system)


#we run our sampling function for the different scenarios/pavement systems that we want to sample
pavement_systems = ['DZOAB, B', 'DZOAB, B, PVI', 'DZOAB, A', 'DZOAB, A, PVI']

for pavement_system in pavement_systems:
     sampling_generator(pavement_system, 'LHS', 12000, 1)











def correlate_inputs(pavement_system):
    '''Parameters:
    pavement system (string) : name of the pavement system/scenario to be sampled as named in the corresponding excel sheet'''
    for pavement_system in pavement_systems:
        # Create input_df including the samples of pavement_system selected
        input_df = pd.DataFrame(pd.read_excel(download_path, sheet_name=pavement_system))
        # Initialize empty DataFrame corr_input_df
        corr_input_df = pd.DataFrame()
        # Loop through column names of input_df
        for column in input_df.columns:
            # Check if column name contains "A1" or "A2"
            if 'A1' in column or 'A2' in column:
                # If yes, add the column to corr_input_df
                corr_input_df[column] = input_df[column]
        # Create list with materials
        materials = ['bitumen', 'crushedsand', 'crushedstone3', 'ownmaterial', 'mediumfiller', 'dripresistantmaterial']
        # Loop through the materials list
        for material in materials:
            # Create a filter to select columns that start with "A1" and contain the material string
            a1_columns = [col for col in corr_input_df.columns if col.startswith('A1') and material in col]
            # Create a filter to select columns that start with "A2" and contain the material string
            a2_columns = [col for col in corr_input_df.columns if col.startswith('A2') and material in col]
            # Update values in A2 columns based on corresponding values in A1 columns
            for a1_col, a2_col in zip(a1_columns, a2_columns):
                corr_input_df[a2_col] = corr_input_df[a2_col] * corr_input_df[a1_col]
        # Iterate over columns of corr_input_df
        for column in corr_input_df.columns:
            # Update values in input_df columns with the same name
            input_df[column] = corr_input_df[column]
        #Save correlated samples dataframe
        with pd.ExcelWriter(download_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
            input_df.to_excel(writer, sheet_name = pavement_system)

            



    
    






