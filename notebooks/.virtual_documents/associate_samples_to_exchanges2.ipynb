


%load_ext autoreload
%autoreload 2


from pprint import pprint

import bw2analyzer as bwa
import bw2calc as bc
import bw2data as bd
import bw2io as bi
import bw_processing as bwp
import numpy as np

# import ipywidgets as widgets
import pandas as pd
from bw2data.query import Filter, Query
from IPython.display import display
from tqdm import autonotebook


from project_details import EI_DB_NAME, PROJECT_NAME


bd.projects.set_current(PROJECT_NAME)
bd.databases


# Is the background database name the same as the one we wrote in `propject_details.py`?
assert EI_DB_NAME in bd.databases


FG_DB_NAME = "asphalt"


db_asphalt = bd.Database(FG_DB_NAME)


pavement_complete_a = db_asphalt.get("DZOAB, A")


bwa.print_recursive_supply_chain(pavement_complete_a, max_level=1)








pavement_mats = bd.get_activity(25964)
print(pavement_mats)
for e in pavement_mats.technosphere():
    print(e)





for e in pavement_mats.technosphere():
    if "comments" in e.as_dict():
        # print(e["comments"])
        pprint(e["comments"])


def exchange_coords(exchange):
    """create a tuple with the numerical ids of the input and output activites of an exchange."""
    input_activity = bd.get_activity(exchange["input"])
    output_activity = bd.get_activity(exchange["output"])
    return (input_activity.id, output_activity.id)


# We can create tuples of coords for every non "production" exchange of an activity like this.
for e in pavement_mats.technosphere():
    print(exchange_coords(e))





samples_df = pd.read_excel(
    "Samples.xlsx", sheet_name=pavement_complete_a["name"], dtype=float, index_col=0
)
samples_df.head()


samples_df.columns





def sample_name_for_exchange(exchange, phase):
    """Return the sample name to use for this exchange."""
    all_names_mapping = {
        "A1": {
            "bitumen": "A1_bitumen",
            "crushed sand": "A1_crushedsand",
            "crushed stone": "A1_crushedstone3",
            "rap": "A1_asphaltgranulate",
            "own material": "A1_ownmaterial",
            "filler": "A1_mediumfiller",
            "drip resistant material": "A1_dripresistantmaterial",
        },
        "A2": {
            "bitumen": "A2_bitumen",
            "filler": "A2_mediumfiller",
            "drip resistant material": "A2_dripresistantmaterial",
        },
    }

    if "A1" == phase:
        names_mapping = all_names_mapping[phase]
        col_name = names_mapping[exchange["comments"]]
    if "A2" == phase:
        names_mapping = all_names_mapping[phase]
        if exchange["comments"] in names_mapping:
            return names_mapping[exchange["comments"]]
        else:
            input_activity = bd.get_activity(exchange["input"])
            comments = exchange["comments"]
            var_name = exchange["comments"].replace(" ", "")
            if var_name == "crushedstone":
                var_name = var_name + "3"
            ref_prod = input_activity["reference product"]
            if ref_prod == "transport, freight, sea, ferry":
                suffix = "sv"
            if ref_prod == "transport, freight, inland waterways, barge":
                suffix = "iv"
            if ref_prod == "transport, freight, lorry, unspecified":
                suffix = "t"
            col_name = f"{phase}_{var_name}_{suffix}"
    if "A3" == phase:
        input_activity = bd.get_activity(exchange["input"])
        ref_prod = input_activity["reference product"]
        if ref_prod == "electricity, low voltage":
            col_name = f"{phase}_electricity"
        elif ref_prod == "heat, district or industrial, natural gas":
            col_name = f"{phase}_naturalgas"
        elif ref_prod == "diesel, burned in building machine":
            col_name = f"{phase}_diesel"
    if "A4" == phase or "C2" == phase:
        input_activity = bd.get_activity(exchange["input"])
        ref_prod = input_activity["reference product"]
        if ref_prod in [
            "transport, freight, lorry >32 metric ton, EURO5",
            "transport, freight, lorry >32 metric ton, EURO6",
        ]:
            col_name = f"{phase}_distance"
    if "A5" == phase:
        col_name = f"{phase}_construction"
    if "C1" == phase:
        comments = exchange["comments"]
        var_name = exchange["comments"].lower()
        col_name = f"{phase}_{var_name}"
    if "C3" == phase:
        col_name = f"{phase}_craneandshovel"

    return col_name


def build_coords_sample(activity, samples_df):
    """Build the coords + sample dictionnary for all phases of activity.

    The activities are the top level "pavement complete" producing ones:

    [0]: DZOAB, A, PVI (pavement, complete, NL)
    [1]: DZOAB, B, PVI (pavement, complete, NL)
    [2]: DZOAB, B (pavement, complete, NL)
    [3]: DZOAB, A (pavement, complete, NL)

    """
    # Make sure we have a valid activity to start with
    assert "pavement, complete" == activity["reference product"]
    coords_samples_map = {}

    # the phases are for example: A1, pavement, materials, A
    # We must create the coords_sample for the inputs of each "phase"
    phase_exchanges = [input for input in activity.technosphere()]

    for phase_exchange in phase_exchanges:
        input_activity = bd.get_activity(phase_exchange["input"])
        # pprint(input_activity)
        # mapping = build_mapping(input_activity)
        # print(mapping)
        # Extract the "A1", "A2", etc. substring from the phase name
        current_phase = input_activity["name"].split(",")[0]
        for exchange in input_activity.technosphere():
            col_name = sample_name_for_exchange(exchange, current_phase)
            # print(f"{exchange}\n\t ðŸ‘‰ {col_name}")
            coords = exchange_coords(exchange)
            coords_samples_map[exchange_coords(exchange)] = samples_df[
                col_name
            ].values  # numpy.ndarray
    return coords_samples_map


# coords_samples_map = build_coords_sample(pavement_complete_a, samples_df)


# This is how to build the samples but only for the pavement materials activity
coords_samples_map = {}
for e in pavement_mats.technosphere():
    col_name = sample_name_for_exchange(e, "A1")
    print(f"{e} -> {col_name}")
    coords_samples_map[exchange_coords(e)] = samples_df[
        col_name
    ].values  # numpy.ndarray





for k, v in coords_samples_map.items():
    print(f"{k} --array-> {v}")


# cml_methods = [m for m in bd.methods if m[0] == "CML v4.8 2016"]
cml_method_gwp = (
    "CML v4.8 2016",
    "climate change",
    "global warming potential (GWP100)",
)





a_lca = bc.LCA({pavement_complete_a: 1}, cml_method_gwp)


a_lca.lci()
a_lca.lcia()
a_lca.score





# the following function returns:
# indexed_demand, data_objs, remapping_dicts
# that follow the data package spec
indexed_demand, data_objs, remapping_dicts = bd.prepare_lca_inputs(
    {pavement_complete_a: 1}, cml_method_gwp
)


indexed_demand


data_objs


for i in data_objs:
    print(i.metadata["name"])


dp_lca = bc.LCA(demand=indexed_demand, data_objs=data_objs)
dp_lca.lci()
dp_lca.lcia()
dp_lca.score


biosphere_dp = [dp for dp in data_objs if dp.metadata["name"] == "biosphere3"].pop()
biosphere_dp.metadata["name"]


ei_dp = [dp for dp in data_objs if dp.metadata["name"] == EI_DB_NAME].pop()
ei_dp.metadata["name"]


fg_dp = [dp for dp in data_objs if dp.metadata["name"] == "asphalt"].pop()
fg_dp.metadata["name"]


pprint(fg_dp.metadata)


dp_correlated = bwp.create_datapackage(sequential=True)


samples_indices = [coord for coord in coords_samples_map.keys()]
pprint(samples_indices)


# Prepare the data_array, it must be an array of arrays
samples_values = np.array([coords_samples_map[coord] for coord in samples_indices])
pprint(samples_values)


dp_correlated.add_persistent_array(
    matrix="technosphere_matrix",
    indices_array=np.array(samples_indices, dtype=bwp.INDICES_DTYPE),
    data_array=samples_values,
    # We flip the signs of the samples
    # to obey bw's convention
    flip_array=np.array([True for _ in range(len(samples_values))]),
)





data_objs.append(dp_correlated)


dp_lca = bc.LCA(demand=indexed_demand, data_objs=data_objs, use_arrays=True)
dp_lca.lci()
dp_lca.lcia()
dp_lca.score


scores = []
for _ in autonotebook.tqdm(range(400)):
    next(dp_lca)
    scores.append(dp_lca.score)


scores_a = np.array(scores)
scores_a.mean()


scores_a_s = pd.Series(scores_a)


scores_a_s.describe()
